{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBmRwrDfKQma",
        "outputId": "87e4aeda-379a-4183-e2de-f7598eec792c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "DATA_DIR='/content/drive/MyDrive/Colab Notebooks/mesh2matrix/mesh'\n",
        "#old DATA_DIR='/content/drive/MyDrive/mesh'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAxJgYZoUZLj"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/mesh2matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GDqgPfNWAGz",
        "outputId": "8c5ab473-b920-4427-ca96-2b79b53077e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (from -r MeSH2Matrix/requirements.txt (line 1)) (1.79)\n",
            "Requirement already satisfied: gdown>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from -r MeSH2Matrix/requirements.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r MeSH2Matrix/requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r MeSH2Matrix/requirements.txt (line 4)) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r MeSH2Matrix/requirements.txt (line 5)) (1.0.2)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from -r MeSH2Matrix/requirements.txt (line 6)) (1.8.1)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.7/dist-packages (from -r MeSH2Matrix/requirements.txt (line 7)) (0.5.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r MeSH2Matrix/requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: torchtext==0.9.1 in /usr/local/lib/python3.7/dist-packages (from -r MeSH2Matrix/requirements.txt (line 10)) (0.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->-r MeSH2Matrix/requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1->-r MeSH2Matrix/requirements.txt (line 10)) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1->-r MeSH2Matrix/requirements.txt (line 10)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=4.2.0->-r MeSH2Matrix/requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=4.2.0->-r MeSH2Matrix/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=4.2.0->-r MeSH2Matrix/requirements.txt (line 2)) (4.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r MeSH2Matrix/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r MeSH2Matrix/requirements.txt (line 4)) (2022.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r MeSH2Matrix/requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r MeSH2Matrix/requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r MeSH2Matrix/requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: ipython==7.* in /usr/local/lib/python3.7/dist-packages (from livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (7.34.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (2.3.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (0.18.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (3.0.30)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (0.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.*->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (0.2.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MeSH2Matrix/requirements.txt (line 8)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MeSH2Matrix/requirements.txt (line 8)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MeSH2Matrix/requirements.txt (line 8)) (1.4.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (21.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (5.1.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (2.11.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot->-r MeSH2Matrix/requirements.txt (line 7)) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r MeSH2Matrix/requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r MeSH2Matrix/requirements.txt (line 10)) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r MeSH2Matrix/requirements.txt (line 10)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r MeSH2Matrix/requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r MeSH2Matrix/requirements.txt (line 10)) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r MeSH2Matrix/requirements.txt\n",
        "!pip install livelossplot --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TBGMHA_KZwy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchtext\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,f1_score\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if True and torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "NUM_CLASSES=195\n",
        "BATCH_SIZE=128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idPlJk3ZMzEZ"
      },
      "source": [
        "MeSH Dataset Class..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b0Ea3PrMwgo"
      },
      "outputs": [],
      "source": [
        "class MESHDataset(Dataset):\n",
        "    def __init__(self,numpy_file,label_file):\n",
        "     \n",
        "      try:\n",
        "        self.data= np.load(numpy_file)\n",
        "        self.labels = np.load(label_file)\n",
        "      except Exception as err:\n",
        "        raise Exception(f'ERROR OPENING FILES: {numpy_file} | {label_file}. See Error below. \\n {err}')  \n",
        "       \n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "    def __getitem__(self, idx):\n",
        "        #Get the element with `idx`\n",
        "        #Output an 89*89 matrix\n",
        "        return np.expand_dims(self.data[idx], axis=0), self.labels[idx]\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHTH6wwuMxCj"
      },
      "source": [
        "Baseline Model..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUZY6XrPKtnF"
      },
      "outputs": [],
      "source": [
        "class InceptionModel(nn.Module):\n",
        "\n",
        "    def __init__(self, matrix_size=89):\n",
        "      #Idea\n",
        "      \"\"\"\n",
        "      ConvNet -> ConvNet -> Flatten ->  Dense => Class \n",
        "      \"\"\"\n",
        "      super(InceptionModel, self).__init__()\n",
        "      self.layer1 = nn.Sequential(\n",
        "          nn.Conv2d(1, 128, kernel_size=3, stride=1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "          nn.Conv2d(128,64, kernel_size=3, stride=1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "          nn.Conv2d(64,32, kernel_size=3, stride=1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "          )\n",
        "      self.layer2 = nn.Sequential(\n",
        "          nn.Conv2d(32, 16, kernel_size=3, stride=1),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "      \n",
        "      self.drop_out = nn.Dropout()\n",
        "      self.fc = nn.Sequential(\n",
        "          #nn.Linear(12800, 5000),\n",
        "          #nn.ReLU(),\n",
        "          #nn.Linear(5000, 1000),\n",
        "          #nn.ReLU(),\n",
        "          nn.Linear(2592,1024),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(1024,500),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(500,NUM_CLASSES)\n",
        "      )\n",
        "    def forward(self, x):\n",
        "\n",
        "        #Expecting `x` to be an 89*89 matrix. \n",
        "        #print(f'X original shape: {x.shape}')\n",
        "        x=self.layer1(x)\n",
        "        #x = self.layer2(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        #print(f'Flattened X has shape: {x.shape}')\n",
        "        x=self.drop_out(x)\n",
        "        x=self.fc(x)\n",
        "        #out = F.log_softmax(x) #Don't use softmax here since we use torch.nn.CrossEntropyLoss. \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyl1ZGauMx2D"
      },
      "source": [
        "Creating the dataloaders..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L6bBWrQQ7ZY"
      },
      "outputs": [],
      "source": [
        "train_dataset = MESHDataset(os.path.join(DATA_DIR,'output/train.npy'),os.path.join(DATA_DIR,'output/train_labels.npy'))\n",
        "dev_dataset = MESHDataset(os.path.join(DATA_DIR,'output/dev.npy'),os.path.join(DATA_DIR,'output/dev_labels.npy'))\n",
        "test_dataset = MESHDataset(os.path.join(DATA_DIR,'output/test.npy'),os.path.join(DATA_DIR,'output/test_labels.npy'))\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Ii7wyjRJU7",
        "outputId": "907116e2-49b4-4694-92f4-04207920baa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: 33457\n",
            "dev shape: 13012\n",
            "test shape: 9294\n",
            "train shape: 33457\n",
            "dev shape: 13012\n",
            "test shape: 9294\n"
          ]
        }
      ],
      "source": [
        "print(f'train shape: {len(train_dataset)}')\n",
        "print(f'dev shape: {len(dev_dataset)}')\n",
        "print(f'test shape: {len(test_dataset)}')\n",
        "\n",
        "print(f'train shape: {train_dataset.__len__()}')\n",
        "print(f'dev shape: {dev_dataset.__len__()}')\n",
        "print(f'test shape: {test_dataset.__len__()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8NQ8K3gRqfY",
        "outputId": "c41ee8d0-3f2c-4430-daf8-48a12d43e015"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46469"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)+len(dev_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csOitTpM3_G"
      },
      "source": [
        "Creating the model...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_SMJMdyM5ay",
        "outputId": "d385e6c7-fc03-4127-d629-d438a01d4fee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InceptionModel(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU()\n",
              "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (drop_out): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2592, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=500, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=500, out_features=195, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model = InceptionModel().to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vExAV-0PM8rX"
      },
      "source": [
        "Training Configuration..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUkMvhaOWZTj"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "def compute_accuracy(pred,target):  \n",
        "  acc = (target == pred.argmax(dim=1)).float().detach().numpy()\n",
        "  return float(100 * acc.sum() / len(acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "EIj8vMcrM-3i",
        "outputId": "4e88d629-1edb-4c77-fea3-bfb2bc9357ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor epoch in range(NUM_EPOCHS):\\n  for i,(features, label) in enumerate(train_dataloader):\\n    features, label = features.to(device), label.to(device)\\n    optimizer.zero_grad()\\n    pred = model(features.float())\\n    loss = criterion(pred,label)\\n\\n   \\n    \\n    loss.backward()\\n    optimizer.step()\\n\\n    if i%DO_VALIDATION_STEP==0:\\n      #Do validation\\n      model.eval()\\n      val_losses=[]\\n      val_acc_list=[]\\n      for val_features, val_label in dev_dataloader:\\n         val_features, val_label = val_features.to(device), val_label.to(device)\\n         val_pred = model(val_features.float())\\n         val_loss = criterion(val_pred,val_label)\\n         val_losses.append(val_loss.item())\\n         val_acc_list.append(compute_accuracy(val_pred.cpu(),val_label.cpu()))\\n\\n      val_loss_ = np.mean(val_losses) \\n      val_acc = np.mean(val_acc_list)\\n      if val_acc> best_acc:\\n        best_acc=val_acc\\n        patience=0\\n        #Save model weights\\n        torch.save(model.state_dict(), PATH)\\n      else:\\n        patience+=1\\n      if patience >= PATIENCE:\\n        break    \\n      \\n      logs={'loss':loss.item(),'val_loss':val_loss_,'val_accuracy':val_acc}\\n      liveloss.update(logs)\\n      liveloss.send()  \\n      model.train()  \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Define criterion: Categorical cross entropy\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#Define optimizer. For now, Adam\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "PRINT_FREQ = 5\n",
        "DO_VALIDATION_STEP=30\n",
        "NUM_EPOCHS=1500\n",
        "PATIENCE=50\n",
        "\n",
        "PATH=os.path.join(DATA_DIR,'output/best_model_cnn_best_128')\n",
        "\n",
        "if os.path.isfile(PATH):\n",
        "  model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "patience=0\n",
        "\n",
        "'''\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for i,(features, label) in enumerate(train_dataloader):\n",
        "    features, label = features.to(device), label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(features.float())\n",
        "    loss = criterion(pred,label)\n",
        "\n",
        "   \n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%DO_VALIDATION_STEP==0:\n",
        "      #Do validation\n",
        "      model.eval()\n",
        "      val_losses=[]\n",
        "      val_acc_list=[]\n",
        "      for val_features, val_label in dev_dataloader:\n",
        "         val_features, val_label = val_features.to(device), val_label.to(device)\n",
        "         val_pred = model(val_features.float())\n",
        "         val_loss = criterion(val_pred,val_label)\n",
        "         val_losses.append(val_loss.item())\n",
        "         val_acc_list.append(compute_accuracy(val_pred.cpu(),val_label.cpu()))\n",
        "\n",
        "      val_loss_ = np.mean(val_losses) \n",
        "      val_acc = np.mean(val_acc_list)\n",
        "      if val_acc> best_acc:\n",
        "        best_acc=val_acc\n",
        "        patience=0\n",
        "        #Save model weights\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "      else:\n",
        "        patience+=1\n",
        "      if patience >= PATIENCE:\n",
        "        break    \n",
        "      \n",
        "      logs={'loss':loss.item(),'val_loss':val_loss_,'val_accuracy':val_acc}\n",
        "      liveloss.update(logs)\n",
        "      liveloss.send()  \n",
        "      model.train()  \n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dft_hV2rGWG"
      },
      "source": [
        "Compute test metrics... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjz6mz5m6nix"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def compute_accuracy(pred, target):\n",
        "  return target.detach().numpy(), pred.argmax(-1).detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TCbQzZyrFDg",
        "outputId": "4e6d49f3-97de-4cec-912f-4de664f4e00a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best CNN Model Accuracy with 195 classes:0.7048633527006671\n",
            "Best CNN Model Weighted F1-Score with 195 classes: 0.6617880913997406\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "labels, preds = [], []\n",
        "for test_features, test_label in test_dataloader:\n",
        "  # print(test_features.size())\n",
        "  test_features, test_label = test_features.to(device), test_label.to(device)\n",
        "  test_pred = model(test_features.float())\n",
        "  true, predictions = compute_accuracy(test_pred.cpu(),test_label.cpu())\n",
        "  labels += true.tolist()\n",
        "  preds += predictions.tolist()\n",
        "print(f'Best CNN Model Accuracy with 195 classes:{accuracy_score(labels, preds)}')\n",
        "print(\"Best CNN Model Weighted F1-Score with 195 classes: {}\".format(f1_score(labels, preds, average='weighted')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MossHpLGjw0"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_orSg5hCic0",
        "outputId": "1a3761d2-0e68-4212-9d07-c2a937cc0ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0 52  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n"
          ]
        }
      ],
      "source": [
        "confusion= confusion_matrix(labels, preds)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(np.unique(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BcA8gvbfuEH",
        "outputId": "3ba89e6f-eac7-49f2-b691-1d9ef5571462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFgWej2Ge03n",
        "outputId": "d9eaaedf-9816-466d-c253-a051fbfd8418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CNN_MeSH Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}